# Pipeline ETL Pand√©mies 

Pipeline ETL professionnel pour l'analyse comparative des donn√©es COVID-19 et MPOX avec **extraction automatis√©e**, **profiling avanc√©**, **visualisations automatiques** et **transformation harmonis√©e**.

## Objectif

Ce projet vise √† cr√©er un pipeline ETL robuste et reproductible pour :
- **Extraire** automatiquement les donn√©es COVID-19 et MPOX depuis les sources officielles
- **Analyser** et **visualiser** les donn√©es avec des graphiques professionnels
- **Transformer** et **harmoniser** les donn√©es pour l'analyse comparative
- **Charger** les donn√©es dans une base PostgreSQL optimis√©e pour l'analyse

---

## Structure du projet

```
ETL/
‚îú‚îÄ‚îÄ raw_data/          # Donn√©es brutes t√©l√©charg√©es
‚îú‚îÄ‚îÄ processed/         # Donn√©es transform√©es et pr√™tes
‚îú‚îÄ‚îÄ graphs/            # Visualisations g√©n√©r√©es automatiquement
‚îú‚îÄ‚îÄ logs/              # Logs d'ex√©cution d√©taill√©s
‚îú‚îÄ‚îÄ scripts/           # Scripts Python du pipeline ETL
‚îú‚îÄ‚îÄ docs/              # Documentation professionnelle
‚îî‚îÄ‚îÄ venv/              # Environnement virtuel Python
```

---

## Installation et configuration

### 1. Pr√©requis
- **Python 3.8+**
- **Git**
- **PostgreSQL** (pour le chargement final)

### 2. Installation
   ```powershell
# Cloner le projet
git clone <repository-url>
cd MSPR/ETL

# Cr√©er l'environnement virtuel
   python -m venv venv
   .\venv\Scripts\Activate.ps1

# Installer les d√©pendances
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

---

## Utilisation - Pipeline ETL complet

### Option 1 : Pipeline automatis√© complet (RECOMMAND√â)
```powershell
cd scripts
python run_etl_pipeline.py
```

**Ex√©cute automatiquement :**
1. **Extraction** : T√©l√©chargement s√©curis√© des donn√©es
2. **Profiling** : Analyse exploratoire avec visualisations
3. **Transformation** : Nettoyage et harmonisation
4. **Validation** : V√©rification des r√©sultats

### Option 2 : Ex√©cution √©tape par √©tape

#### 1. Extraction automatis√©e
```powershell
python 01_extract.py
```
**Fonctionnalit√©s :**
- T√©l√©chargement automatique depuis Our World in Data
- V√©rification d'int√©grit√© avec checksums SHA-256
- Gestion d'erreurs avec retry automatique
- Logging d√©taill√© et tra√ßabilit√© compl√®te

#### 2. Profiling et analyse exploratoire
```powershell
python 02_profile.py
```
**Visualisations automatiques g√©n√©r√©es :**
- **Histogrammes** : Distribution des cas et d√©c√®s
- **Boxplots** : Analyse des outliers et variabilit√©
- **Heatmaps** : Corr√©lations entre variables
- **Graphiques temporels** : √âvolution des pand√©mies
- **Analyse comparative** : COVID-19 vs MPOX
- **Top pays** : Impact g√©ographique
- **M√©triques avanc√©es** : L√©talit√©, saisonnalit√©

#### 3. Transformation et nettoyage
```powershell
python 03_transform.py
```
**Fonctionnalit√©s :**
- Harmonisation des sch√©mas COVID-19 et MPOX
- Normalisation des noms de pays et codes ISO
- Calcul des m√©triques d√©riv√©es (incidence 7j, croissance)
- G√©n√©ration des tables de dimension

#### 4. Tests de validation (optionnel)
```powershell
python test_extract.py      # Tests de l'extraction
python test_coherence.py    # Tests de coh√©rence globale
```

---

## üìä Scripts du pipeline ETL

| Script | Fonction | Description |
|--------|----------|-------------|
| `01_extract.py` | **Extraction** | T√©l√©chargement s√©curis√© des donn√©es brutes |
| `02_profile.py` | **Profiling** | Analyse exploratoire + visualisations automatiques |
| `03_transform.py` | **Transformation** | Nettoyage, harmonisation et enrichissement |
| `run_etl_pipeline.py` | **Orchestration** | Pipeline complet automatis√© |
| `test_extract.py` | **Tests** | Validation du module d'extraction |
| `test_coherence.py` | **Tests** | Validation de la coh√©rence globale |

---

## Visualisations g√©n√©r√©es

### Graphiques par source
- `graphs/covid_analysis.png` : 6 graphiques COVID-19
- `graphs/mpox_analysis.png` : 6 graphiques MPOX

### Analyse comparative
- `graphs/comparative_analysis.png` : 8 graphiques comparatifs

### Types de visualisations
1. **Distributions** : Histogrammes avec √©chelle log
2. **Outliers** : Boxplots pour d√©tection d'anomalies
3. **Corr√©lations** : Heatmaps des relations
4. **√âvolution temporelle** : Tendances et pics √©pid√©miques
5. **Comparaisons** : Analyse COVID vs MPOX
6. **G√©ographie** : Top pays par impact
7. **M√©triques** : L√©talit√© et saisonnalit√©

---

## Sources de donn√©es

### COVID-19 - Our World in Data
- **URL** : `https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv`
- **Format** : CSV (~50MB)
- **P√©riode** : 2020-2024
- **Granularit√©** : Quotidienne par pays

### MPOX - Our World in Data
- **URL** : `https://raw.githubusercontent.com/owid/monkeypox/main/owid-monkeypox-data.csv`
- **Format** : CSV (~2MB)
- **P√©riode** : 2022-2024
- **Granularit√©** : Quotidienne par pays

**Justification du choix :** Our World in Data est une organisation reconnue mondialement pour la qualit√© et la standardisation de ses donn√©es √©pid√©miologiques.

---

## Analyse exploratoire int√©gr√©e

### M√©triques calcul√©es automatiquement
- **Statistiques descriptives** : Moyenne, m√©diane, √©cart-type, quartiles
- **Distributions** : Histogrammes avec d√©tection de patterns
- **Corr√©lations** : Matrices de corr√©lation compl√®tes
- **Tendances** : √âvolution temporelle et saisonnalit√©
- **Comparaisons** : Analyse comparative d√©taill√©e

### Rapports g√©n√©r√©s
- **Rapport textuel** : `logs/profiling_report_YYYYMMDD_HHMMSS.txt`
- **Interpr√©tations** : `logs/interpretation_report_YYYYMMDD_HHMMSS.md`
- **Visualisations** : `graphs/` (PNG 300 DPI)
- **Logs d√©taill√©s** : Tra√ßabilit√© compl√®te

---

## Documentation d√©taill√©e

### Documentation par √©tape
- `docs/01_extraction_justification.md` : Extraction automatis√©e
- `docs/02_profiling_analyse.md` : Profiling et visualisations
- `docs/03_transformation_nettoyage.md` : Transformation et nettoyage
- `docs/04_orchestration_pipeline.md` : Orchestration du pipeline
- `docs/05_tests_validation.md` : Tests et validation
- `docs/06_loading_data.md` : Choix architectural du loading

### Documentation technique
- `docs/benchmark_etl.md` : Comparaison Python vs Talend vs Apache Hop

---

## R√©sultats attendus

### Fichiers de donn√©es transform√©es
- `processed/fact_covid_history.csv` : Donn√©es COVID harmonis√©es
- `processed/fact_mpox_history.csv` : Donn√©es MPOX harmonis√©es
- `processed/dim_country.csv` : R√©f√©rentiel des pays
- `processed/dim_indicator.csv` : R√©f√©rentiel des indicateurs

### Suite du pipeline
**Le chargement (Loading) des donn√©es est impl√©ment√© dans la partie BDD :**
- **Script** : `BDD/src/scripts/load_data.js`
- **Technologie** : Node.js + Prisma + PostgreSQL
- **Justification** : Coh√©rence de stack, int√©gration Prisma, gain de temps de d√©veloppement

**Voir** `docs/06_loading_data.md` pour la justification d√©taill√©e de ce choix architectural.

---

## Performance et qualit√©

### M√©triques de performance
- **Extraction** : ~2 minutes pour 50MB de donn√©es
- **Profiling** : ~3 minutes avec g√©n√©ration de 20+ graphiques
- **Transformation** : ~1 minute pour l'harmonisation compl√®te
- **Validation** : Tests automatis√©s en < 30 secondes

### Qualit√© des donn√©es
- **Int√©grit√©** : V√©rification des checksums SHA-256
- **Coh√©rence** : Validation des sch√©mas et contraintes
- **Compl√©tude** : D√©tection des donn√©es manquantes
- **Tra√ßabilit√©** : Logs d√©taill√©s √† chaque √©tape

